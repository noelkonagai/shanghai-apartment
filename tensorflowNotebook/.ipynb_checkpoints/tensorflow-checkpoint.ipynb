{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Tensorflow predictive model based on housing price data for Shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('priceData.csv')\n",
    "raw_data = raw_data.dropna(axis = 0, how = 'any')\n",
    "#raw_data.room = raw_data.room.astype('category')\n",
    "# raw_data.renovation = raw_data.renovation.astype('category')\n",
    "raw_data.lvgroom = raw_data.lvgroom.astype('int64')\n",
    "# raw_data.floor = raw_data.floor.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting statistical values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>7214.722717</td>\n",
       "      <td>4382.403296</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3520.500000</td>\n",
       "      <td>6841.500000</td>\n",
       "      <td>11184.500000</td>\n",
       "      <td>15184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqm</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>107.751112</td>\n",
       "      <td>61.923839</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2.246009</td>\n",
       "      <td>0.934408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lvgroom</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>1.593562</td>\n",
       "      <td>0.616656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2000.418477</td>\n",
       "      <td>9.864450</td>\n",
       "      <td>1918.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renovation</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2.767208</td>\n",
       "      <td>0.708619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>12337.277807</td>\n",
       "      <td>11213.236025</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>31.208627</td>\n",
       "      <td>0.086148</td>\n",
       "      <td>30.707683</td>\n",
       "      <td>31.194303</td>\n",
       "      <td>31.221302</td>\n",
       "      <td>31.241236</td>\n",
       "      <td>31.407696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lng</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>121.481631</td>\n",
       "      <td>0.073207</td>\n",
       "      <td>121.103223</td>\n",
       "      <td>121.434194</td>\n",
       "      <td>121.492974</td>\n",
       "      <td>121.534738</td>\n",
       "      <td>121.711090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>200495.652185</td>\n",
       "      <td>666.868666</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200085.000000</td>\n",
       "      <td>200125.000000</td>\n",
       "      <td>201112.000000</td>\n",
       "      <td>215332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_1</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2555.574457</td>\n",
       "      <td>5747.939179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>44700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_2</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>4264.197854</td>\n",
       "      <td>6801.667891</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>47200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count           mean           std            min            25%  \\\n",
       "Unnamed: 0  7642.0    7214.722717   4382.403296       2.000000    3520.500000   \n",
       "sqm         7642.0     107.751112     61.923839       8.000000      64.000000   \n",
       "room        7642.0       2.246009      0.934408       1.000000       2.000000   \n",
       "lvgroom     7642.0       1.593562      0.616656       0.000000       1.000000   \n",
       "year        7642.0    2000.418477      9.864450    1918.000000    1996.000000   \n",
       "renovation  7642.0       2.767208      0.708619       1.000000       2.000000   \n",
       "price       7642.0   12337.277807  11213.236025    1000.000000    5500.000000   \n",
       "lat         7642.0      31.208627      0.086148      30.707683      31.194303   \n",
       "lng         7642.0     121.481631      0.073207     121.103223     121.434194   \n",
       "postal      7642.0  200495.652185    666.868666  200000.000000  200085.000000   \n",
       "dist_1      7642.0    2555.574457   5747.939179       0.000000     800.000000   \n",
       "dist_2      7642.0    4264.197854   6801.667891     300.000000    1400.000000   \n",
       "\n",
       "                      50%            75%            max  \n",
       "Unnamed: 0    6841.500000   11184.500000   15184.000000  \n",
       "sqm             97.000000     135.000000     731.000000  \n",
       "room             2.000000       3.000000      11.000000  \n",
       "lvgroom          2.000000       2.000000       4.000000  \n",
       "year          2003.000000    2006.000000    2017.000000  \n",
       "renovation       3.000000       3.000000       4.000000  \n",
       "price         9000.000000   15000.000000  200000.000000  \n",
       "lat             31.221302      31.241236      31.407696  \n",
       "lng            121.492974     121.534738     121.711090  \n",
       "postal      200125.000000  201112.000000  215332.000000  \n",
       "dist_1        1200.000000    2000.000000   44700.000000  \n",
       "dist_2        2100.000000    3700.000000   47200.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "x_data = raw_data.drop(['price'],axis=1)\n",
    "y_data = raw_data['price']\n",
    "\n",
    "x_train, x_test, y_train, y_test = tts(x_data, y_data, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqm\n",
      "year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat\n",
      "lng\n",
      "dist_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['sqm', 'year', 'lat', 'lng', 'dist_1',]\n",
    "\n",
    "for item in numeric_columns:\n",
    "    print(item)\n",
    "    scaler.fit(x_train[item])\n",
    "    scaler.fit(x_train[item])\n",
    "    x_train[item] = scaler.transform(x_train[item])\n",
    "    x_test[item] = scaler.transform(x_test[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.feature_column.embedding_column('room', dimension = len(raw_data))\n",
    "\n",
    "f1 = tf.feature_column.numeric_column('sqm')\n",
    "f2 = tf.feature_column.numeric_column('year')\n",
    "f3 = tf.feature_column.numeric_column('dist_1')\n",
    "f4 = tf.feature_column.categorical_column_with_hash_bucket(\"room\", hash_bucket_size=11)\n",
    "f4 = tf.feature_column.categorical_column_with_hash_bucket(key = 'room', hash_bucket_size = 11)\n",
    "f5 = tf.feature_column.categorical_column_with_hash_bucket(key = 'renovation', hash_bucket_size = 5, dtype = tf.string)\n",
    "f6 = tf.feature_column.categorical_column_with_hash_bucket(key = 'lvgroom', hash_bucket_size = 5, dtype = tf.string)\n",
    "f7 = tf.feature_column.categorical_column_with_hash_bucket(key = 'floor', hash_bucket_size = 3, dtype = tf.string)\n",
    "\n",
    "embedded_columns = [tf.feature_column.embedding_column(f4, 1),\n",
    "           tf.feature_column.embedding_column(f5, 1),\n",
    "           tf.feature_column.embedding_column(f6, 1),\n",
    "           tf.feature_column.embedding_column(f7, 1)]\n",
    "\n",
    "features = tf.parse_example(features = tf.feature_column.make_parse_example_spec(columns))\n",
    "dense_tensor = input_layer(features, columns)\n",
    "\n",
    "feature_columns = [f1, f2, f3] + dense_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size = 10,\n",
    "    num_epochs = 1000,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/j5/j768nzj554jbgl0ypv8vxk640000gp/T/tmpfhrhs01g\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/j5/j768nzj554jbgl0ypv8vxk640000gp/T/tmpfhrhs01g', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x118a179e8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(\n",
    "    hidden_units = [3,12,32,12,3],\n",
    "    feature_columns = feature_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Column dtype and SparseTensors dtype must be compatible. key: lvgroom, column dtype: <dtype: 'string'>, tensor dtype: <dtype: 'int64'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-81958514bbd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.train(input_fn = input_func, \n\u001b[0;32m----> 2\u001b[0;31m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m            )\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step_read_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 711\u001b[0;31m             features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    712\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    452\u001b[0m           \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m           config=config)\n\u001b[0m\u001b[1;32m    455\u001b[0m     super(DNNRegressor, self).__init__(\n\u001b[1;32m    456\u001b[0m         model_fn=_model_fn, model_dir=model_dir, config=config)\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[0;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         input_layer_partitioner=input_layer_partitioner)\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train_op_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[0;34m(features, mode)\u001b[0m\n\u001b[1;32m     87\u001b[0m         partitioner=input_layer_partitioner):\n\u001b[1;32m     88\u001b[0m       net = feature_column_lib.input_layer(\n\u001b[0;32m---> 89\u001b[0;31m           features=features, feature_columns=feature_columns)\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_units\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mweight_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             trainable=trainable)\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_get_dense_tensor\u001b[0;34m(self, inputs, weight_collections, trainable)\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;31m# Get sparse IDs and weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m     sparse_tensors = self.categorical_column._get_sparse_tensors(  # pylint: disable=protected-access\n\u001b[0;32m-> 1834\u001b[0;31m         inputs, weight_collections=weight_collections, trainable=trainable)\n\u001b[0m\u001b[1;32m   1835\u001b[0m     \u001b[0msparse_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m     \u001b[0msparse_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_get_sparse_tensors\u001b[0;34m(self, inputs, weight_collections, trainable)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   def _get_sparse_tensors(self, inputs, weight_collections=None,\n\u001b[1;32m   2014\u001b[0m                           trainable=None):\n\u001b[0;32m-> 2015\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_CategoricalColumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdWeightPair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1531\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transforming feature_column %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Column {} is not supported.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noelkonagai/anaconda/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_transform_feature\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1994\u001b[0m           \u001b[0;34m'Column dtype and SparseTensors dtype must be compatible. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m           'key: {}, column dtype: {}, tensor dtype: {}'.format(\n\u001b[0;32m-> 1996\u001b[0;31m               self.key, self.dtype, input_tensor.dtype))\n\u001b[0m\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Column dtype and SparseTensors dtype must be compatible. key: lvgroom, column dtype: <dtype: 'string'>, tensor dtype: <dtype: 'int64'>"
     ]
    }
   ],
   "source": [
    "model.train(input_fn = input_func, \n",
    "            steps = 5000,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x = x_test,\n",
    "      batch_size = 10,\n",
    "      num_epochs = 1,\n",
    "      shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred_gen = model.predict(predict_input_func)\n",
    "predictions = list(pred_gen)\n",
    "\n",
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])\n",
    "\n",
    "print(mean_squared_error(y_test,final_preds)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
