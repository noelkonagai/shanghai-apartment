{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Tensorflow predictive model based on housing price data for Shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelkonagai/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('priceData.csv')\n",
    "raw_data = raw_data.dropna(axis = 0, how = 'any')\n",
    "raw_data.room = raw_data.room.astype('int64')\n",
    "raw_data.renovation = raw_data.renovation.astype('int64')\n",
    "raw_data.lvgroom = raw_data.lvgroom.astype('int64')\n",
    "# raw_data.floor = raw_data.floor.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting statistical values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>7214.722717</td>\n",
       "      <td>4382.403296</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3520.500000</td>\n",
       "      <td>6841.500000</td>\n",
       "      <td>11184.500000</td>\n",
       "      <td>15184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqm</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>107.751112</td>\n",
       "      <td>61.923839</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2.246009</td>\n",
       "      <td>0.934408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lvgroom</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>1.593562</td>\n",
       "      <td>0.616656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2000.418477</td>\n",
       "      <td>9.864450</td>\n",
       "      <td>1918.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renovation</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2.767208</td>\n",
       "      <td>0.708619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>12337.277807</td>\n",
       "      <td>11213.236025</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>31.208627</td>\n",
       "      <td>0.086148</td>\n",
       "      <td>30.707683</td>\n",
       "      <td>31.194303</td>\n",
       "      <td>31.221302</td>\n",
       "      <td>31.241236</td>\n",
       "      <td>31.407696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lng</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>121.481631</td>\n",
       "      <td>0.073207</td>\n",
       "      <td>121.103223</td>\n",
       "      <td>121.434194</td>\n",
       "      <td>121.492974</td>\n",
       "      <td>121.534738</td>\n",
       "      <td>121.711090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>200495.652185</td>\n",
       "      <td>666.868666</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200085.000000</td>\n",
       "      <td>200125.000000</td>\n",
       "      <td>201112.000000</td>\n",
       "      <td>215332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_1</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2555.574457</td>\n",
       "      <td>5747.939179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>44700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_2</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>4264.197854</td>\n",
       "      <td>6801.667891</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>47200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count           mean           std            min            25%  \\\n",
       "Unnamed: 0  7642.0    7214.722717   4382.403296       2.000000    3520.500000   \n",
       "sqm         7642.0     107.751112     61.923839       8.000000      64.000000   \n",
       "room        7642.0       2.246009      0.934408       1.000000       2.000000   \n",
       "lvgroom     7642.0       1.593562      0.616656       0.000000       1.000000   \n",
       "year        7642.0    2000.418477      9.864450    1918.000000    1996.000000   \n",
       "renovation  7642.0       2.767208      0.708619       1.000000       2.000000   \n",
       "price       7642.0   12337.277807  11213.236025    1000.000000    5500.000000   \n",
       "lat         7642.0      31.208627      0.086148      30.707683      31.194303   \n",
       "lng         7642.0     121.481631      0.073207     121.103223     121.434194   \n",
       "postal      7642.0  200495.652185    666.868666  200000.000000  200085.000000   \n",
       "dist_1      7642.0    2555.574457   5747.939179       0.000000     800.000000   \n",
       "dist_2      7642.0    4264.197854   6801.667891     300.000000    1400.000000   \n",
       "\n",
       "                      50%            75%            max  \n",
       "Unnamed: 0    6841.500000   11184.500000   15184.000000  \n",
       "sqm             97.000000     135.000000     731.000000  \n",
       "room             2.000000       3.000000      11.000000  \n",
       "lvgroom          2.000000       2.000000       4.000000  \n",
       "year          2003.000000    2006.000000    2017.000000  \n",
       "renovation       3.000000       3.000000       4.000000  \n",
       "price         9000.000000   15000.000000  200000.000000  \n",
       "lat             31.221302      31.241236      31.407696  \n",
       "lng            121.492974     121.534738     121.711090  \n",
       "postal      200125.000000  201112.000000  215332.000000  \n",
       "dist_1        1200.000000    2000.000000   44700.000000  \n",
       "dist_2        2100.000000    3700.000000   47200.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "x_data = raw_data.drop(['price'],axis=1)\n",
    "y_data = raw_data['price']\n",
    "\n",
    "x_train, x_test, y_train, y_test = tts(x_data, y_data, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqm\n",
      "year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat\n",
      "lng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/noelkonagai/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['sqm', 'year', 'lat', 'lng', 'dist_1',]\n",
    "\n",
    "for item in numeric_columns:\n",
    "    print(item)\n",
    "    scaler.fit(x_train[item])\n",
    "    scaler.fit(x_train[item])\n",
    "    x_train[item] = scaler.transform(x_train[item])\n",
    "    x_test[item] = scaler.transform(x_test[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.feature_column.embedding_column('room', dimension = len(raw_data))\n",
    "\n",
    "f1 = tf.feature_column.numeric_column('sqm')\n",
    "f2 = tf.feature_column.numeric_column('year')\n",
    "f3 = tf.feature_column.numeric_column('dist_1')\n",
    "f4 = tf.feature_column.categorical_column_with_hash_bucket(\"room\", hash_bucket_size=11)\n",
    "f4 = tf.feature_column.categorical_column_with_hash_bucket(key = 'room', hash_bucket_size = 11, dtype = tf.int64)\n",
    "f5 = tf.feature_column.categorical_column_with_hash_bucket(key = 'renovation', hash_bucket_size = 5, dtype = tf.int64)\n",
    "f6 = tf.feature_column.categorical_column_with_hash_bucket(key = 'lvgroom', hash_bucket_size = 5, dtype = tf.int64)\n",
    "f7 = tf.feature_column.categorical_column_with_hash_bucket(key = 'floor', hash_bucket_size = 3, dtype = tf.string)\n",
    "\n",
    "embedded_columns = [tf.feature_column.embedding_column(f4, 1),\n",
    "           tf.feature_column.embedding_column(f5, 1),\n",
    "           tf.feature_column.embedding_column(f6, 1),\n",
    "           tf.feature_column.embedding_column(f7, 1)]\n",
    "\n",
    "#features = tf.parse_example(features = tf.feature_column.make_parse_example_spec(embedded_columns))\n",
    "#dense_tensor = input_layer(features, embedded_columns)\n",
    "\n",
    "feature_columns = [f1, f2] + embedded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size = 100,\n",
    "    num_epochs = 3000,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/j5/j768nzj554jbgl0ypv8vxk640000gp/T/tmpzdy1hy9u\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/j5/j768nzj554jbgl0ypv8vxk640000gp/T/tmpzdy1hy9u', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11ade8c88>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(\n",
    "    hidden_units = [7,14,28,14,7],\n",
    "    feature_columns = feature_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/j5/j768nzj554jbgl0ypv8vxk640000gp/T/tmpzdy1hy9u/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.36187e+10, step = 1\n",
      "INFO:tensorflow:global_step/sec: 133.936\n",
      "INFO:tensorflow:loss = 3.93277e+09, step = 101 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.162\n",
      "INFO:tensorflow:loss = 3.23867e+09, step = 201 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.683\n",
      "INFO:tensorflow:loss = 3.54725e+10, step = 301 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.661\n",
      "INFO:tensorflow:loss = 7.04707e+09, step = 401 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.434\n",
      "INFO:tensorflow:loss = 2.96994e+09, step = 501 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.036\n",
      "INFO:tensorflow:loss = 6.6512e+09, step = 601 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.261\n",
      "INFO:tensorflow:loss = 4.22098e+09, step = 701 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.508\n",
      "INFO:tensorflow:loss = 4.6672e+09, step = 801 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.684\n",
      "INFO:tensorflow:loss = 5.9366e+09, step = 901 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.429\n",
      "INFO:tensorflow:loss = 1.15845e+10, step = 1001 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.981\n",
      "INFO:tensorflow:loss = 2.86396e+09, step = 1101 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.261\n",
      "INFO:tensorflow:loss = 4.98157e+09, step = 1201 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.202\n",
      "INFO:tensorflow:loss = 2.59176e+09, step = 1301 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.559\n",
      "INFO:tensorflow:loss = 2.64414e+09, step = 1401 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.57\n",
      "INFO:tensorflow:loss = 2.08748e+09, step = 1501 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.231\n",
      "INFO:tensorflow:loss = 1.78374e+09, step = 1601 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.347\n",
      "INFO:tensorflow:loss = 3.11067e+09, step = 1701 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.055\n",
      "INFO:tensorflow:loss = 1.16859e+10, step = 1801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.186\n",
      "INFO:tensorflow:loss = 9.8125e+09, step = 1901 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.116\n",
      "INFO:tensorflow:loss = 2.06639e+09, step = 2001 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.661\n",
      "INFO:tensorflow:loss = 2.16934e+09, step = 2101 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.721\n",
      "INFO:tensorflow:loss = 3.92458e+09, step = 2201 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.948\n",
      "INFO:tensorflow:loss = 2.15505e+09, step = 2301 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.51\n",
      "INFO:tensorflow:loss = 2.27352e+09, step = 2401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.748\n",
      "INFO:tensorflow:loss = 2.53799e+09, step = 2501 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.229\n",
      "INFO:tensorflow:loss = 3.88674e+09, step = 2601 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.495\n",
      "INFO:tensorflow:loss = 2.1324e+09, step = 2701 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.221\n",
      "INFO:tensorflow:loss = 3.37483e+09, step = 2801 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.998\n",
      "INFO:tensorflow:loss = 2.51007e+09, step = 2901 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.375\n",
      "INFO:tensorflow:loss = 3.64588e+09, step = 3001 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.181\n",
      "INFO:tensorflow:loss = 1.87796e+09, step = 3101 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.025\n",
      "INFO:tensorflow:loss = 2.48218e+09, step = 3201 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.313\n",
      "INFO:tensorflow:loss = 3.53648e+09, step = 3301 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.206\n",
      "INFO:tensorflow:loss = 6.41328e+09, step = 3401 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.233\n",
      "INFO:tensorflow:loss = 1.9637e+09, step = 3501 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.045\n",
      "INFO:tensorflow:loss = 2.10443e+09, step = 3601 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.049\n",
      "INFO:tensorflow:loss = 1.70383e+09, step = 3701 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.578\n",
      "INFO:tensorflow:loss = 1.2312e+09, step = 3801 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.14\n",
      "INFO:tensorflow:loss = 1.43329e+09, step = 3901 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.598\n",
      "INFO:tensorflow:loss = 2.03588e+09, step = 4001 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.032\n",
      "INFO:tensorflow:loss = 3.98211e+09, step = 4101 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.575\n",
      "INFO:tensorflow:loss = 6.7238e+09, step = 4201 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.013\n",
      "INFO:tensorflow:loss = 3.15689e+09, step = 4301 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.65\n",
      "INFO:tensorflow:loss = 2.15307e+09, step = 4401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.767\n",
      "INFO:tensorflow:loss = 2.86519e+09, step = 4501 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.952\n",
      "INFO:tensorflow:loss = 2.55504e+09, step = 4601 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.471\n",
      "INFO:tensorflow:loss = 2.10331e+09, step = 4701 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.132\n",
      "INFO:tensorflow:loss = 1.60273e+09, step = 4801 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.074\n",
      "INFO:tensorflow:loss = 7.25568e+09, step = 4901 (0.398 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/j5/j768nzj554jbgl0ypv8vxk640000gp/T/tmpzdy1hy9u/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.51653e+09.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x11ade8d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn = input_func, \n",
    "            steps = 5000,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x = x_test,\n",
    "      batch_size = 10,\n",
    "      num_epochs = 1,\n",
    "      shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/j5/j768nzj554jbgl0ypv8vxk640000gp/T/tmpzdy1hy9u/model.ckpt-5000\n",
      "5941.43407404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred_gen = model.predict(predict_input_func)\n",
    "predictions = list(pred_gen)\n",
    "\n",
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])\n",
    "\n",
    "print(mean_squared_error(y_test,final_preds)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
