{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Tensorflow predictive model based on housing price data for Shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noel/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/price_data.csv'\n",
    "\n",
    "raw_data = pd.read_csv(path)\n",
    "raw_data = raw_data.dropna(axis = 0, how = 'any')\n",
    "raw_data.room = raw_data.room.astype('int64')\n",
    "raw_data.renovation = raw_data.renovation.astype('int64')\n",
    "raw_data.lvgroom = raw_data.lvgroom.astype('int64')\n",
    "raw_data.sqm = raw_data.sqm.astype('float64')\n",
    "# raw_data.floor = raw_data.floor.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting statistical values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>7214.722717</td>\n",
       "      <td>4382.403296</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3520.500000</td>\n",
       "      <td>6841.500000</td>\n",
       "      <td>11184.500000</td>\n",
       "      <td>15184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqm</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>107.751112</td>\n",
       "      <td>61.923839</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2.246009</td>\n",
       "      <td>0.934408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lvgroom</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>1.593562</td>\n",
       "      <td>0.616656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2000.418477</td>\n",
       "      <td>9.864450</td>\n",
       "      <td>1918.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renovation</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2.767208</td>\n",
       "      <td>0.708619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>12337.277807</td>\n",
       "      <td>11213.236025</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>31.208627</td>\n",
       "      <td>0.086148</td>\n",
       "      <td>30.707683</td>\n",
       "      <td>31.194303</td>\n",
       "      <td>31.221302</td>\n",
       "      <td>31.241236</td>\n",
       "      <td>31.407696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lng</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>121.481631</td>\n",
       "      <td>0.073207</td>\n",
       "      <td>121.103223</td>\n",
       "      <td>121.434194</td>\n",
       "      <td>121.492974</td>\n",
       "      <td>121.534738</td>\n",
       "      <td>121.711090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postal</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>200495.652185</td>\n",
       "      <td>666.868666</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200085.000000</td>\n",
       "      <td>200125.000000</td>\n",
       "      <td>201112.000000</td>\n",
       "      <td>215332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_1</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>2555.574457</td>\n",
       "      <td>5747.939179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>44700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_2</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>4264.197854</td>\n",
       "      <td>6801.667891</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>47200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count           mean           std            min            25%  \\\n",
       "Unnamed: 0  7642.0    7214.722717   4382.403296       2.000000    3520.500000   \n",
       "sqm         7642.0     107.751112     61.923839       8.000000      64.000000   \n",
       "room        7642.0       2.246009      0.934408       1.000000       2.000000   \n",
       "lvgroom     7642.0       1.593562      0.616656       0.000000       1.000000   \n",
       "year        7642.0    2000.418477      9.864450    1918.000000    1996.000000   \n",
       "renovation  7642.0       2.767208      0.708619       1.000000       2.000000   \n",
       "price       7642.0   12337.277807  11213.236025    1000.000000    5500.000000   \n",
       "lat         7642.0      31.208627      0.086148      30.707683      31.194303   \n",
       "lng         7642.0     121.481631      0.073207     121.103223     121.434194   \n",
       "postal      7642.0  200495.652185    666.868666  200000.000000  200085.000000   \n",
       "dist_1      7642.0    2555.574457   5747.939179       0.000000     800.000000   \n",
       "dist_2      7642.0    4264.197854   6801.667891     300.000000    1400.000000   \n",
       "\n",
       "                      50%            75%            max  \n",
       "Unnamed: 0    6841.500000   11184.500000   15184.000000  \n",
       "sqm             97.000000     135.000000     731.000000  \n",
       "room             2.000000       3.000000      11.000000  \n",
       "lvgroom          2.000000       2.000000       4.000000  \n",
       "year          2003.000000    2006.000000    2017.000000  \n",
       "renovation       3.000000       3.000000       4.000000  \n",
       "price         9000.000000   15000.000000  200000.000000  \n",
       "lat             31.221302      31.241236      31.407696  \n",
       "lng            121.492974     121.534738     121.711090  \n",
       "postal      200125.000000  201112.000000  215332.000000  \n",
       "dist_1        1200.000000    2000.000000   44700.000000  \n",
       "dist_2        2100.000000    3700.000000   47200.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "x_data = raw_data.drop(['price'],axis=1)\n",
    "y_data = raw_data['price']\n",
    "\n",
    "x_train, x_test, y_train, y_test = tts(x_data, y_data, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[102. 164. 135. ... 123. 138.  61.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6effee395218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumeric_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noel/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noel/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         X = check_array(X, copy=self.copy, warn_on_dtype=True,\n\u001b[0;32m--> 334\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/noel/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[102. 164. 135. ... 123. 138.  61.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['sqm', 'year', 'lat', 'lng', 'dist_1',]\n",
    "\n",
    "for item in numeric_columns:\n",
    "    print(item)\n",
    "    scaler.fit(x_train[item])\n",
    "    scaler.fit(x_train[item])\n",
    "    x_train[item] = scaler.transform(x_train[item])\n",
    "    x_test[item] = scaler.transform(x_test[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "Starting off with seven features, later adding metro stations as one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.feature_column.embedding_column('room', dimension = len(raw_data))\n",
    "\n",
    "f1 = tf.feature_column.numeric_column('sqm')\n",
    "f2 = tf.feature_column.numeric_column('year')\n",
    "f3 = tf.feature_column.numeric_column('dist_1')\n",
    "f4 = tf.feature_column.categorical_column_with_hash_bucket(\"room\", hash_bucket_size=300)\n",
    "f4 = tf.feature_column.categorical_column_with_hash_bucket(key = 'room', hash_bucket_size = 300, dtype = tf.int64)\n",
    "f5 = tf.feature_column.categorical_column_with_hash_bucket(key = 'renovation', hash_bucket_size = 100, dtype = tf.int64)\n",
    "f6 = tf.feature_column.categorical_column_with_hash_bucket(key = 'lvgroom', hash_bucket_size = 100, dtype = tf.int64)\n",
    "f7 = tf.feature_column.categorical_column_with_hash_bucket(key = 'floor', hash_bucket_size = 100, dtype = tf.string)\n",
    "\n",
    "numeric_columns = [f1, f2, f3]\n",
    "\n",
    "embedded_columns = [tf.feature_column.embedding_column(f4, 1),\n",
    "           tf.feature_column.embedding_column(f5, 1),\n",
    "           tf.feature_column.embedding_column(f6, 1),\n",
    "           tf.feature_column.embedding_column(f7, 1)]\n",
    "\n",
    "feature_columns = numeric_columns + embedded_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_func(batch_size, num_epochs):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size = batch_size,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DNN_model(hidden_units, activation_fn, feature_columns):\n",
    "\n",
    "    return tf.estimator.DNNRegressor(\n",
    "    hidden_units = hidden_units,\n",
    "    feature_columns = feature_columns,\n",
    "    activation_fn = activation_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_func = tf.estimator.inputs.pandas_input_fn(\n",
    "        x = x_test,\n",
    "        batch_size = 10,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(predictions):\n",
    "    \n",
    "    final_preds = []\n",
    "    for pred in predictions:\n",
    "        final_preds.append(pred['predictions'])\n",
    "    \n",
    "    return mean_squared_error(y_test,final_preds)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A1 = DNN_model([7,14,28,14,7], tf.nn.crelu, feature_columns)\n",
    "\n",
    "model_A1.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_A1.predict(predict_func)\n",
    "predictions_A1 = list(pred_gen)\n",
    "rmse(predictions_A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A2 = DNN_model([7,14,28,14,7], tf.nn.softplus, feature_columns)\n",
    "\n",
    "model_A2.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_A2.predict(predict_func)\n",
    "predictions_A2 = list(pred_gen)\n",
    "rmse(predictions_A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A3 = DNN_model([7,14,28,14,7], tf.nn.elu, feature_columns)\n",
    "\n",
    "model_A3.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_A3.predict(predict_func)\n",
    "predictions_A3 = list(pred_gen)\n",
    "rmse(predictions_A3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A4 = DNN_model([7,14,28,14,7], tf.nn.relu6, feature_columns)\n",
    "\n",
    "model_A4.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_A4.predict(predict_func)\n",
    "predictions_A4 = list(pred_gen)\n",
    "rmse(predictions_A4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A5 = DNN_model([7,14,28,14,7], tf.nn.relu, feature_columns)\n",
    "\n",
    "model_A5.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_A5.predict(predict_func)\n",
    "predictions_A5 = list(pred_gen)\n",
    "rmse(predictions_A5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Metro Station as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f8_bucket_size = raw_data.station_1.nunique()\n",
    "\n",
    "f8 = tf.feature_column.categorical_column_with_hash_bucket(key = 'station_1', hash_bucket_size = f8_bucket_size, dtype = tf.string)\n",
    "\n",
    "feature_columns_v2 = numeric_columns + embedded_columns + [tf.feature_column.embedding_column(f8, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layers [7,14,28,14,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B1 = DNN_model([7,14,28,14,7], tf.nn.crelu, feature_columns_v2)\n",
    "\n",
    "model_B1.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_B1.predict(predict_func)\n",
    "predictions_B1 = list(pred_gen)\n",
    "rmse(predictions_B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layers = [8,16,32,16,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B2 = DNN_model([8,16,32,16,8], tf.nn.crelu, feature_columns_v2)\n",
    "\n",
    "model_B2.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_B2.predict(predict_func)\n",
    "predictions_B2 = list(pred_gen)\n",
    "rmse(predictions_B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B3 = DNN_model([6,12,24,12,6], tf.nn.crelu, feature_columns_v2)\n",
    "\n",
    "model_B3.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_B3.predict(predict_func)\n",
    "predictions_B3 = list(pred_gen)\n",
    "rmse(predictions_B3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B4 = DNN_model([7,12,28,12,7], tf.nn.crelu, feature_columns_v2)\n",
    "\n",
    "model_B4.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_B4.predict(predict_func)\n",
    "predictions_B4 = list(pred_gen)\n",
    "rmse(predictions_B4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: LatLng vs. Metro Station\n",
    "Which of these features is more predictive of the price? For this, I have created a crossed LatLng feature column. In order to do so, first the LatLng data was binned to 100 bins each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_bins = pd.cut(raw_data['lat'], 100, retbins = True, right = True, include_lowest = True)[1]\n",
    "lng_bins = pd.cut(raw_data['lng'], 100, retbins = True)[1]\n",
    "\n",
    "f9 = tf.feature_column.numeric_column('lat')\n",
    "f10 = tf.feature_column.numeric_column('lng')\n",
    "bucketized_lat = tf.feature_column.bucketized_column(f9, list(lat_bins))\n",
    "bucketized_lng = tf.feature_column.bucketized_column(f10, list(lng_bins))\n",
    "\n",
    "crossed_lat_lng = tf.feature_column.crossed_column([bucketized_lat, bucketized_lng], 100*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_v3 = feature_columns + [tf.feature_column.embedding_column(crossed_lat_lng,1)]\n",
    "\n",
    "model_C1 = DNN_model([7,14,28,14,7], tf.nn.crelu, feature_columns_v3)\n",
    "\n",
    "model_C1.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_C1.predict(predict_func)\n",
    "predictions_C1 = list(pred_gen)\n",
    "rmse(predictions_C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_C2 = DNN_model([5,12,32,12,8], tf.nn.crelu, feature_columns_v3)\n",
    "\n",
    "model_C2.train(\n",
    "    input_fn = input_func(100,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_C2.predict(predict_func)\n",
    "predictions_C2 = list(pred_gen)\n",
    "rmse(predictions_C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_C3 = DNN_model([5,12,32,12,5], tf.nn.crelu, feature_columns_v3)\n",
    "\n",
    "model_C3.train(\n",
    "    input_fn = input_func(140,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_C3.predict(predict_func)\n",
    "predictions_C3 = list(pred_gen)\n",
    "rmse(predictions_C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_C4 = DNN_model([5,12,25,12,5], tf.nn.crelu, feature_columns_v3)\n",
    "\n",
    "model_C4.train(\n",
    "    input_fn = input_func(140,3000), \n",
    "    steps = 5000,\n",
    "    )\n",
    "\n",
    "pred_gen = model_C4.predict(predict_func)\n",
    "predictions_C4 = list(pred_gen)\n",
    "rmse(predictions_C4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
